<!DOCTYPE html>
<html style="background-color: black; color: white;">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>WebXR Pose Data</title>
    <style>
      body, html {
        margin: 0;
        padding: 0;
        background-color: black;
        color: white;
        font-family: Arial, sans-serif;
      }
      button {
        font-size: 24px;
        padding: 10px;
        position: fixed;
        top: 10px;
        right: 10px;
      }
      #pose {
        margin-top: 80px;
        text-align: center;
        font-size: 20px;
        white-space: pre-wrap;
      }
      #overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: black;
        z-index: -1;  /* Place behind the button and pose text */
      }
    </style>
    <script src="textToSpeech.js"></script>
  </head>
  <body>
    <div id="overlay"></div>
    <!-- A single Start/Stop button -->
    <button id="xr-button" disabled>XR not found</button>
    <!-- Pose data will be printed here on mobile screen -->
    <div id="pose">Pose data will appear here.</div>

    <script>
      let xrSession = null;
      let xrRefSpace = null;
      const xrButton = document.getElementById('xr-button');
      const poseDiv = document.getElementById('pose');
      let ws = null;
      let cameraStarted = false;
      let lastCameraFrame = null;
      let tts = null;  // Change from instantiation to null
      let isSessionActive = false;  // Add this flag to track session state
      let videoTrack = null;  // Add this to track camera stream

      // Check if immersive-ar session is supported
      function checkSupported() {
        if (navigator.xr) {
          navigator.xr.isSessionSupported('immersive-ar').then(supported => {
            xrButton.disabled = !supported;
            xrButton.textContent = supported ? 'Start' : 'XR not found';
          });
        } else {
          xrButton.disabled = true;
          xrButton.textContent = 'XR not supported';
        }
      }
      checkSupported();
      navigator.xr && navigator.xr.addEventListener('devicechange', checkSupported);

      // Toggle start/stop when button is clicked
      xrButton.addEventListener('click', () => {
        if (!xrSession) {
          startSession();
        } else {
          console.log('Ending XR session...');
          xrSession.end();
          // No need to call onSessionEnded here as it's called by the event listener
        }
      });

      function connectWebSocket() {
        if (!isSessionActive) return;  // Don't connect if session isn't active
        
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${protocol}//${window.location.host}`;
        
        ws = new WebSocket(wsUrl);
        ws.onopen = () => console.log('Sensor WebSocket connected');
        ws.onerror = (error) => console.error('Sensor WebSocket error:', error);
        ws.onclose = () => {
          if (isSessionActive) {  // Only reconnect if session is still active
            console.log('Sensor WebSocket closed, reconnecting...');
            setTimeout(connectWebSocket, 1000);
          }
        };
      }

      // Add camera streaming function
      async function startCamera() {
        if (cameraStarted || !isSessionActive) return;
        try {
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            throw new Error('getUserMedia API not supported');
          }

          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "user" },
          });
          videoTrack = stream.getVideoTracks()[0];  // Store video track reference
          
          const trackProcessor = new MediaStreamTrackProcessor({ track: videoTrack });
          const reader = trackProcessor.readable.getReader();

          let lastSentTime = 0;
          const desiredFps = 2;
          const frameInterval = 1000 / desiredFps;

          async function sendFrames() {
            while (true) {
              const { done, value: videoFrame } = await reader.read();
              if (done) break;

              const currentTime = performance.now();
              if (currentTime - lastSentTime < frameInterval) {
                videoFrame.close();
                continue;
              }
              lastSentTime = currentTime;

              if (ws && ws.readyState === WebSocket.OPEN) {
                const bitmap = await createImageBitmap(videoFrame);
                videoFrame.close();

                if (!sendFrames.canvas) {
                  sendFrames.canvas = new OffscreenCanvas(bitmap.width, bitmap.height);
                  sendFrames.ctx = sendFrames.canvas.getContext('2d');
                }
                const { canvas, ctx } = sendFrames;
                ctx.drawImage(bitmap, 0, 0);

                const blob = await canvas.convertToBlob({ type: 'image/jpeg', quality: 0.7 });
                const buffer = await blob.arrayBuffer();
                // Store as base64 string
                lastCameraFrame = btoa(String.fromCharCode(...new Uint8Array(buffer)));
              }
            }
          }

          sendFrames().catch(console.error);
          cameraStarted = true;
        } catch (err) {
          console.error('Camera error:', err);
          alert('Camera access failed: ' + err.message);
        }
      }

      // Start immersive-ar session without extra UI parts
      async function startSession() {
        try {
          xrSession = await navigator.xr.requestSession('immersive-ar', {
            requiredFeatures: ['local'],
            optionalFeatures: ['dom-overlay'],
            domOverlay: { root: document.body },
            environmentBlendMode: 'opaque'
          });
          xrButton.textContent = 'Stop';
          xrSession.addEventListener('end', onSessionEnded);

          // Create WebGL context but don't attach canvas to document
          const canvas = document.createElement('canvas');
          const gl = canvas.getContext('webgl', { xrCompatible: true });
          await xrSession.updateRenderState({
            baseLayer: new XRWebGLLayer(xrSession, gl)
          });

          xrRefSpace = await xrSession.requestReferenceSpace('local');
          xrSession.requestAnimationFrame(onXRFrame);

          isSessionActive = true;  // Set flag when starting
          
          // Initialize TTS with proper voice loading
          tts = new TextToSpeech();
          await tts.connectWebSocket(); // This now includes voice initialization
          
          connectWebSocket();
          startCamera();

        } catch (e) {
          console.error('Failed to start XR session:', e);
          isSessionActive = false;  // Reset flag if start fails
          if (tts) {
            tts.disconnectWebSocket();
            tts = null;
          }
        }
      }

      // When the session ends, reset button and display
      function onSessionEnded() {
        console.log('Session ending: Cleaning up resources...');
        isSessionActive = false;  // Clear flag first
        
        if (ws) {
          console.log('Closing sensor WebSocket');
          ws.close();
          ws = null;
        }

        if (tts) {
          console.log('Closing TTS system');
          tts.disconnectWebSocket();
          tts = null;
        }

        if (videoTrack) {
          console.log('Stopping camera track');
          videoTrack.stop();  // Properly stop the camera
          videoTrack = null;
        }

        cameraStarted = false;
        xrSession = null;
        xrButton.textContent = 'Start';
        poseDiv.textContent = 'Session ended.';
        console.log('Cleanup complete');
      }

      // Frame loop: update and publish pose data
      function onXRFrame(time, frame) {
        xrSession.requestAnimationFrame(onXRFrame);
        const pose = frame.getViewerPose(xrRefSpace);
        if (pose) {
          const pos = pose.transform.position;
          const o = pose.transform.orientation;
          const text = `Position: ${pos.x.toFixed(3)}, ${pos.y.toFixed(3)}, ${pos.z.toFixed(3)}
            Orientation: ${o.x.toFixed(3)}, ${o.y.toFixed(3)}, ${o.z.toFixed(3)}, ${o.w.toFixed(3)}`;
          // Print on mobile screen
          poseDiv.textContent = text;
          
          // Send unified data via WebSocket
          if (ws && ws.readyState === WebSocket.OPEN) {
            const unifiedData = {
              timestamp: Date.now(),
              pose: {
                position: { x: pos.x, y: pos.y, z: pos.z },
                orientation: { x: o.x, y: o.y, z: o.z, w: o.w }
              },
              camera: lastCameraFrame
            };
            ws.send(JSON.stringify(unifiedData));
            // Clear camera frame after sending
            lastCameraFrame = null;
          }
        } else {
          poseDiv.textContent = 'No pose available.';
        }
      }
    </script>
  </body>
</html>
